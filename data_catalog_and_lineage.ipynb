{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248a80e9",
   "metadata": {},
   "source": [
    "# Data Catalog And Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22bee0",
   "metadata": {},
   "source": [
    "## Data Catalog and Lineage\n",
    "\n",
    "This notebook handles the documentation and tracking of data assets, their origins, and transformations.\n",
    "It establishes a system for maintaining metadata about datasets and tracking how data flows through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d4c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import uuid\n",
    "import os\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data structures for metadata and lineage tracking\n",
    "@dataclass\n",
    "class ColumnMetadata:\n",
    "    \"\"\"Metadata for a single column in a dataset.\"\"\"\n",
    "    name: str\n",
    "    data_type: str\n",
    "    description: str = \"\"\n",
    "    nullable: bool = True\n",
    "    unique_values: int = 0\n",
    "    min_value: Optional[Any] = None\n",
    "    max_value: Optional[Any] = None\n",
    "    sample_values: List[Any] = field(default_factory=list)\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    statistics: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class DatasetMetadata:\n",
    "    \"\"\"Metadata for a dataset.\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    description: str\n",
    "    created_at: str\n",
    "    updated_at: str\n",
    "    version: str\n",
    "    source: str\n",
    "    owner: str\n",
    "    columns: List[ColumnMetadata] = field(default_factory=list)\n",
    "    row_count: int = 0\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    additional_info: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class Transformation:\n",
    "    \"\"\"Information about a data transformation.\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    description: str\n",
    "    code: str\n",
    "    created_at: str\n",
    "    input_datasets: List[str] = field(default_factory=list)\n",
    "    output_datasets: List[str] = field(default_factory=list)\n",
    "    parameters: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class DataLineage:\n",
    "    \"\"\"Data lineage information.\"\"\"\n",
    "    dataset_id: str\n",
    "    transformations: List[Transformation] = field(default_factory=list)\n",
    "    upstream_datasets: List[str] = field(default_factory=list)\n",
    "    downstream_datasets: List[str] = field(default_factory=list)\n",
    "\n",
    "class DataCatalog:\n",
    "    \"\"\"A class to manage dataset metadata and lineage.\"\"\"\n",
    "    \n",
    "    def __init__(self, catalog_path=\"./data_catalog\"):\n",
    "        \"\"\"Initialize the data catalog with a storage path.\"\"\"\n",
    "        self.catalog_path = catalog_path\n",
    "        self.metadata_path = os.path.join(catalog_path, \"metadata\")\n",
    "        self.lineage_path = os.path.join(catalog_path, \"lineage\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create directories if they don't exist\n",
    "        os.makedirs(self.metadata_path, exist_ok=True)\n",
    "        os.makedirs(self.lineage_path, exist_ok=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # In-memory cache of metadata and lineage\n",
    "        self.metadata_cache = {}\n",
    "        self.lineage_cache = {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177aa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Load existing metadata and lineage\n",
    "        self._load_catalog()\n",
    "    \n",
    "    def _load_catalog(self):\n",
    "        \"\"\"Load existing metadata and lineage from disk.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186eafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Load metadata\n",
    "        if os.path.exists(self.metadata_path):\n",
    "            for filename in os.listdir(self.metadata_path):\n",
    "                if filename.endswith(\".json\"):\n",
    "                    dataset_id = filename.replace(\".json\", \"\")\n",
    "                    with open(os.path.join(self.metadata_path, filename), 'r') as f:\n",
    "                        metadata_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ed800",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # Convert column metadata dictionaries to objects\n",
    "                        columns = []\n",
    "                        for col_dict in metadata_dict.get(\"columns\", []):\n",
    "                            columns.append(ColumnMetadata(**col_dict))\n",
    "                        metadata_dict[\"columns\"] = columns\n",
    "                        self.metadata_cache[dataset_id] = DatasetMetadata(**metadata_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Load lineage\n",
    "        if os.path.exists(self.lineage_path):\n",
    "            for filename in os.listdir(self.lineage_path):\n",
    "                if filename.endswith(\".json\"):\n",
    "                    dataset_id = filename.replace(\".json\", \"\")\n",
    "                    with open(os.path.join(self.lineage_path, filename), 'r') as f:\n",
    "                        lineage_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2896e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # Convert transformation dictionaries to objects\n",
    "                        transformations = []\n",
    "                        for trans_dict in lineage_dict.get(\"transformations\", []):\n",
    "                            transformations.append(Transformation(**trans_dict))\n",
    "                        lineage_dict[\"transformations\"] = transformations\n",
    "                        self.lineage_cache[dataset_id] = DataLineage(**lineage_dict)\n",
    "    \n",
    "    def generate_dataset_id(self, df, name):\n",
    "        \"\"\"Generate a unique ID for a dataset based on its content and name.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create a hash of the dataframe's first few rows and columns\n",
    "        sample_data = df.head(5).to_json()\n",
    "        hash_input = f\"{name}_{sample_data}_{df.shape}\"\n",
    "        return hashlib.md5(hash_input.encode()).hexdigest()\n",
    "    \n",
    "    def extract_column_metadata(self, df, column_name):\n",
    "        \"\"\"Extract metadata for a single column.\"\"\"\n",
    "        col_data = df[column_name]\n",
    "        col_type = str(col_data.dtype)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22479c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create basic column metadata\n",
    "        col_metadata = ColumnMetadata(\n",
    "            name=column_name,\n",
    "            data_type=col_type,\n",
    "            nullable=col_data.isna().any(),\n",
    "            unique_values=col_data.nunique()\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20808b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Add statistics based on data type\n",
    "        if np.issubdtype(col_data.dtype, np.number):\n",
    "            col_metadata.min_value = col_data.min()\n",
    "            col_metadata.max_value = col_data.max()\n",
    "            col_metadata.statistics = {\n",
    "                \"mean\": col_data.mean(),\n",
    "                \"median\": col_data.median(),\n",
    "                \"std\": col_data.std(),\n",
    "                \"25th_percentile\": col_data.quantile(0.25),\n",
    "                \"75th_percentile\": col_data.quantile(0.75)\n",
    "            }\n",
    "        elif col_data.dtype == 'object' or col_data.dtype.name == 'category':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # For string/categorical columns\n",
    "            value_counts = col_data.value_counts().head(5).to_dict()\n",
    "            col_metadata.statistics = {\n",
    "                \"top_values\": value_counts,\n",
    "                \"mode\": col_data.mode()[0] if not col_data.mode().empty else None\n",
    "            }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Add sample values\n",
    "        col_metadata.sample_values = col_data.dropna().sample(min(5, len(col_data))).tolist()\n",
    "        \n",
    "        return col_metadata\n",
    "    \n",
    "    def register_dataset(self, df, name, description, source, owner, tags=None, additional_info=None):\n",
    "        \"\"\"Register a dataset in the catalog with its metadata.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Generate a unique ID for the dataset\n",
    "        dataset_id = self.generate_dataset_id(df, name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create timestamp\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153de7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Extract column metadata\n",
    "        columns = []\n",
    "        for column in df.columns:\n",
    "            col_metadata = self.extract_column_metadata(df, column)\n",
    "            columns.append(col_metadata)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create dataset metadata\n",
    "        metadata = DatasetMetadata(\n",
    "            id=dataset_id,\n",
    "            name=name,\n",
    "            description=description,\n",
    "            created_at=timestamp,\n",
    "            updated_at=timestamp,\n",
    "            version=\"1.0\",\n",
    "            source=source,\n",
    "            owner=owner,\n",
    "            columns=columns,\n",
    "            row_count=len(df),\n",
    "            tags=tags or [],\n",
    "            additional_info=additional_info or {}\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c58854",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create initial lineage\n",
    "        lineage = DataLineage(\n",
    "            dataset_id=dataset_id,\n",
    "            transformations=[],\n",
    "            upstream_datasets=[],\n",
    "            downstream_datasets=[]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Save metadata and lineage\n",
    "        self.metadata_cache[dataset_id] = metadata\n",
    "        self.lineage_cache[dataset_id] = lineage\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7faac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Write to disk\n",
    "        self._save_metadata(dataset_id)\n",
    "        self._save_lineage(dataset_id)\n",
    "        \n",
    "        return dataset_id\n",
    "    \n",
    "    def _save_metadata(self, dataset_id):\n",
    "        \"\"\"Save dataset metadata to disk.\"\"\"\n",
    "        metadata = self.metadata_cache.get(dataset_id)\n",
    "        if metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Convert to dictionary, handling nested objects\n",
    "            metadata_dict = asdict(metadata)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341278f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Write to file\n",
    "            with open(os.path.join(self.metadata_path, f\"{dataset_id}.json\"), 'w') as f:\n",
    "                json.dump(metadata_dict, f, indent=2)\n",
    "    \n",
    "    def _save_lineage(self, dataset_id):\n",
    "        \"\"\"Save dataset lineage to disk.\"\"\"\n",
    "        lineage = self.lineage_cache.get(dataset_id)\n",
    "        if lineage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Convert to dictionary, handling nested objects\n",
    "            lineage_dict = asdict(lineage)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac45cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Write to file\n",
    "            with open(os.path.join(self.lineage_path, f\"{dataset_id}.json\"), 'w') as f:\n",
    "                json.dump(lineage_dict, f, indent=2)\n",
    "    \n",
    "    def get_dataset_metadata(self, dataset_id):\n",
    "        \"\"\"Retrieve metadata for a dataset.\"\"\"\n",
    "        return self.metadata_cache.get(dataset_id)\n",
    "    \n",
    "    def get_dataset_lineage(self, dataset_id):\n",
    "        \"\"\"Retrieve lineage for a dataset.\"\"\"\n",
    "        return self.lineage_cache.get(dataset_id)\n",
    "    \n",
    "    def record_transformation(self, name, description, code, input_datasets, output_dataset_id, parameters=None):\n",
    "        \"\"\"Record a transformation in the lineage of datasets.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create transformation record\n",
    "        transformation_id = str(uuid.uuid4())\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "        \n",
    "        transformation = Transformation(\n",
    "            id=transformation_id,\n",
    "            name=name,\n",
    "            description=description,\n",
    "            code=code,\n",
    "            created_at=timestamp,\n",
    "            input_datasets=input_datasets,\n",
    "            output_datasets=[output_dataset_id],\n",
    "            parameters=parameters or {}\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Update lineage for the output dataset\n",
    "        if output_dataset_id in self.lineage_cache:\n",
    "            lineage = self.lineage_cache[output_dataset_id]\n",
    "            lineage.transformations.append(transformation)\n",
    "            lineage.upstream_datasets.extend([ds_id for ds_id in input_datasets if ds_id not in lineage.upstream_datasets])\n",
    "            self._save_lineage(output_dataset_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Update lineage for input datasets\n",
    "        for input_id in input_datasets:\n",
    "            if input_id in self.lineage_cache:\n",
    "                input_lineage = self.lineage_cache[input_id]\n",
    "                if output_dataset_id not in input_lineage.downstream_datasets:\n",
    "                    input_lineage.downstream_datasets.append(output_dataset_id)\n",
    "                    self._save_lineage(input_id)\n",
    "        \n",
    "        return transformation_id\n",
    "    \n",
    "    def update_dataset_metadata(self, dataset_id, df=None, **kwargs):\n",
    "        \"\"\"Update metadata for a dataset.\"\"\"\n",
    "        if dataset_id in self.metadata_cache:\n",
    "            metadata = self.metadata_cache[dataset_id]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79baa03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Update provided fields\n",
    "            for key, value in kwargs.items():\n",
    "                if hasattr(metadata, key):\n",
    "                    setattr(metadata, key, value)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a71202",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Update timestamp\n",
    "            metadata.updated_at = datetime.datetime.now().isoformat()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Update dataframe-related metadata if provided\n",
    "            if df is not None:\n",
    "                metadata.row_count = len(df)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeade51",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Update column metadata\n",
    "                new_columns = []\n",
    "                for column in df.columns:\n",
    "                    col_metadata = self.extract_column_metadata(df, column)\n",
    "                    new_columns.append(col_metadata)\n",
    "                metadata.columns = new_columns\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc43fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Save updated metadata\n",
    "            self._save_metadata(dataset_id)\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def visualize_lineage(self, dataset_id, depth=2):\n",
    "        \"\"\"Visualize the lineage of a dataset.\"\"\"\n",
    "        try:\n",
    "            import networkx as nx\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            G = nx.DiGraph()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Helper function to recursively add nodes and edges\n",
    "            def add_lineage(ds_id, current_depth=0):\n",
    "                if current_depth > depth:\n",
    "                    return\n",
    "                \n",
    "                if ds_id not in self.lineage_cache:\n",
    "                    return\n",
    "                \n",
    "                lineage = self.lineage_cache[ds_id]\n",
    "                metadata = self.metadata_cache.get(ds_id, None)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Add the current dataset node\n",
    "                node_label = metadata.name if metadata else ds_id\n",
    "                G.add_node(ds_id, label=node_label)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Add upstream datasets\n",
    "                for upstream_id in lineage.upstream_datasets:\n",
    "                    upstream_metadata = self.metadata_cache.get(upstream_id, None)\n",
    "                    upstream_label = upstream_metadata.name if upstream_metadata else upstream_id\n",
    "                    G.add_node(upstream_id, label=upstream_label)\n",
    "                    G.add_edge(upstream_id, ds_id)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e375d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # Recursively add upstream lineage\n",
    "                    add_lineage(upstream_id, current_depth + 1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Add downstream datasets\n",
    "                for downstream_id in lineage.downstream_datasets:\n",
    "                    downstream_metadata = self.metadata_cache.get(downstream_id, None)\n",
    "                    downstream_label = downstream_metadata.name if downstream_metadata else downstream_id\n",
    "                    G.add_node(downstream_id, label=downstream_label)\n",
    "                    G.add_edge(ds_id, downstream_id)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4124f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # Recursively add downstream lineage\n",
    "                    add_lineage(downstream_id, current_depth + 1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Start building the graph\n",
    "            add_lineage(dataset_id)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Draw the graph\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(G)\n",
    "            nx.draw(G, pos, with_labels=False, node_color='skyblue', node_size=1500, arrows=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5816fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Add labels with dataset names instead of IDs\n",
    "            labels = nx.get_node_attributes(G, 'label')\n",
    "            nx.draw_networkx_labels(G, pos, labels=labels)\n",
    "            \n",
    "            plt.title(f\"Data Lineage for {self.metadata_cache.get(dataset_id).name if dataset_id in self.metadata_cache else dataset_id}\")\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"Please install networkx to visualize lineage: pip install networkx\")\n",
    "    \n",
    "    def generate_data_catalog_report(self, output_path=\"data_catalog_report.html\"):\n",
    "        \"\"\"Generate an HTML report of the data catalog.\"\"\"\n",
    "        html = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Data Catalog Report</title>\n",
    "            <style>\n",
    "                body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "                h1 { color: #2c3e50; }\n",
    "                h2 { color: #3498db; margin-top: 30px; }\n",
    "                table { border-collapse: collapse; width: 100%; margin-top: 10px; }\n",
    "                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n",
    "                th { background-color: #f2f2f2; }\n",
    "                tr:nth-child(even) { background-color: #f9f9f9; }\n",
    "                .metadata-section { margin-bottom: 30px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }\n",
    "                .tag { background-color: #e0e0e0; padding: 3px 8px; border-radius: 10px; margin-right: 5px; font-size: 0.8em; }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Data Catalog Report</h1>\n",
    "            <p>Generated on: \"\"\" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\"\"</p>\n",
    "            <p>Total Datasets: \"\"\" + str(len(self.metadata_cache)) + \"\"\"</p>\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Add dataset sections\n",
    "        for dataset_id, metadata in self.metadata_cache.items():\n",
    "            lineage = self.lineage_cache.get(dataset_id, None)\n",
    "            \n",
    "            html += f\"\"\"\n",
    "            <div class=\"metadata-section\">\n",
    "                <h2>{metadata.name}</h2>\n",
    "                <p><strong>ID:</strong> {dataset_id}</p>\n",
    "                <p><strong>Description:</strong> {metadata.description}</p>\n",
    "                <p><strong>Source:</strong> {metadata.source}</p>\n",
    "                <p><strong>Owner:</strong> {metadata.owner}</p>\n",
    "                <p><strong>Created:</strong> {metadata.created_at}</p>\n",
    "                <p><strong>Updated:</strong> {metadata.updated_at}</p>\n",
    "                <p><strong>Version:</strong> {metadata.version}</p>\n",
    "                <p><strong>Row Count:</strong> {metadata.row_count}</p>\n",
    "                <p><strong>Tags:</strong> \"\"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Add tags\n",
    "            for tag in metadata.tags:\n",
    "                html += f'<span class=\"tag\">{tag}</span>'\n",
    "            \n",
    "            html += \"\"\"</p>\n",
    "                \n",
    "                <h3>Columns</h3>\n",
    "                <table>\n",
    "                    <tr>\n",
    "                        <th>Name</th>\n",
    "                        <th>Type</th>\n",
    "                        <th>Nullable</th>\n",
    "                        <th>Unique Values</th>\n",
    "                        <th>Sample Values</th>\n",
    "                    </tr>\n",
    "            \"\"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Add column rows\n",
    "            for column in metadata.columns:\n",
    "                sample_values = \", \".join([str(val) for val in column.sample_values[:3]])\n",
    "                html += f\"\"\"\n",
    "                    <tr>\n",
    "                        <td>{column.name}</td>\n",
    "                        <td>{column.data_type}</td>\n",
    "                        <td>{\"Yes\" if column.nullable else \"No\"}</td>\n",
    "                        <td>{column.unique_values}</td>\n",
    "                        <td>{sample_values}...</td>\n",
    "                    </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            html += \"\"\"\n",
    "                </table>\n",
    "            \"\"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Add lineage information if available\n",
    "            if lineage:\n",
    "                html += \"\"\"\n",
    "                <h3>Data Lineage</h3>\n",
    "                \"\"\"\n",
    "                \n",
    "                if lineage.upstream_datasets:\n",
    "                    html += \"\"\"\n",
    "                    <h4>Upstream Datasets</h4>\n",
    "                    <ul>\n",
    "                    \"\"\"\n",
    "                    for upstream_id in lineage.upstream_datasets:\n",
    "                        upstream_name = self.metadata_cache.get(upstream_id).name if upstream_id in self.metadata_cache else upstream_id\n",
    "                        html += f\"<li>{upstream_name} ({upstream_id})</li>\"\n",
    "                    html += \"</ul>\"\n",
    "                \n",
    "                if lineage.downstream_datasets:\n",
    "                    html += \"\"\"\n",
    "                    <h4>Downstream Datasets</h4>\n",
    "                    <ul>\n",
    "                    \"\"\"\n",
    "                    for downstream_id in lineage.downstream_datasets:\n",
    "                        downstream_name = self.metadata_cache.get(downstream_id).name if downstream_id in self.metadata_cache else downstream_id\n",
    "                        html += f\"<li>{downstream_name} ({downstream_id})</li>\"\n",
    "                    html += \"</ul>\"\n",
    "                \n",
    "                if lineage.transformations:\n",
    "                    html += \"\"\"\n",
    "                    <h4>Transformations</h4>\n",
    "                    <table>\n",
    "                        <tr>\n",
    "                            <th>Name</th>\n",
    "                            <th>Description</th>\n",
    "                            <th>Created</th>\n",
    "                        </tr>\n",
    "                    \"\"\"\n",
    "                    for transformation in lineage.transformations:\n",
    "                        html += f\"\"\"\n",
    "                        <tr>\n",
    "                            <td>{transformation.name}</td>\n",
    "                            <td>{transformation.description}</td>\n",
    "                            <td>{transformation.created_at}</td>\n",
    "                        </tr>\n",
    "                        \"\"\"\n",
    "                    html += \"</table>\"\n",
    "            \n",
    "            html += \"\"\"\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d973a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Write the HTML report to file\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def load_nz_industry_data():\n",
    "    \"\"\"\n",
    "    Load the New Zealand Industry Financial Dataset.\n",
    "    This is a placeholder - in a real scenario, you would load the actual data.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a sample dataframe based on the provided information\n",
    "    data = {\n",
    "        'Year': [2023, 2023, 2023, 2023, 2023],\n",
    "        'Industry_aggregation_NZSIOC': ['Level 1', 'Level 1', 'Level 1', 'Level 1', 'Level 1'],\n",
    "        'Industry_code_NZSIOC': ['99999', '99999', '99999', '99999', '99999'],\n",
    "        'Industry_name_NZSIOC': ['All industries', 'All industries', 'All industries', 'All industries', 'All industries'],\n",
    "        'Units': ['Dollars (millions)', 'Dollars (millions)', 'Dollars (millions)', 'Dollars (millions)', 'Dollars (millions)'],\n",
    "        'Variable_code': ['H01', 'H04', 'H05', 'H07', 'H08'],\n",
    "        'Variable_name': ['Total income', 'Sales, government funding, grants and subsidies', 'Interest, dividends and donations', 'Non-operating income', 'Total expenditure'],\n",
    "        'Variable_category': ['Financial performance', 'Financial performance', 'Financial performance', 'Financial performance', 'Financial performance'],\n",
    "        'Value': ['930995', '821630', '84354', '25010', '832964'],\n",
    "        'Industry_code_ANZSIC06': ['ANZSIC06 divisions A-S (excluding classes K6330, L6711, O7552, O760, O771, O772, S9540, S9601, S9602, and S9603)'] * 5\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca371f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Convert Year to int and Value to numeric\n",
    "    df['Year'] = df['Year'].astype(int)\n",
    "    df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e851234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the data catalog\n",
    "def main():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91de9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize the data catalog\n",
    "    catalog = DataCatalog()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load the raw dataset\n",
    "    print(\"Loading raw dataset...\")\n",
    "    raw_df = load_nz_industry_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Register the raw dataset in the catalog\n",
    "    raw_dataset_id = catalog.register_dataset(\n",
    "        df=raw_df,\n",
    "        name=\"NZ Industry Financial Data - Raw\",\n",
    "        description=\"Raw financial data for New Zealand industries from 2013 to 2023\",\n",
    "        source=\"Annual Enterprise Survey\",\n",
    "        owner=\"Data Science Team\",\n",
    "        tags=[\"finance\", \"new zealand\", \"industry\", \"raw\"],\n",
    "        additional_info={\n",
    "            \"data_collection_method\": \"Annual Enterprise Survey\",\n",
    "            \"coverage_period\": \"2013-2023\",\n",
    "            \"confidentiality\": \"Public\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Raw dataset registered with ID: {raw_dataset_id}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Perform a transformation: Convert Value column to numeric and clean up\n",
    "    print(\"Performing data cleaning transformation...\")\n",
    "    cleaned_df = raw_df.copy()\n",
    "    cleaned_df['Value'] = pd.to_numeric(cleaned_df['Value'], errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Register the cleaned dataset\n",
    "    cleaned_dataset_id = catalog.register_dataset(\n",
    "        df=cleaned_df,\n",
    "        name=\"NZ Industry Financial Data - Cleaned\",\n",
    "        description=\"Cleaned financial data with numeric values\",\n",
    "        source=\"Derived from raw NZ Industry Financial Data\",\n",
    "        owner=\"Data Science Team\",\n",
    "        tags=[\"finance\", \"new zealand\", \"industry\", \"cleaned\"],\n",
    "        additional_info={\n",
    "            \"parent_dataset\": raw_dataset_id,\n",
    "            \"cleaning_steps\": \"Converted Value column to numeric\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Cleaned dataset registered with ID: {cleaned_dataset_id}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Record the transformation\n",
    "    catalog.record_transformation(\n",
    "        name=\"Data Cleaning\",\n",
    "        description=\"Convert Value column to numeric and handle missing values\",\n",
    "        code=\"cleaned_df = raw_df.copy()\\ncleaned_df['Value'] = pd.to_numeric(cleaned_df['Value'], errors='coerce')\",\n",
    "        input_datasets=[raw_dataset_id],\n",
    "        output_dataset_id=cleaned_dataset_id,\n",
    "        parameters={\"errors\": \"coerce\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9655e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Perform another transformation: Calculate year-over-year growth\n",
    "    print(\"Calculating year-over-year growth...\")\n",
    "    growth_df = cleaned_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # This would be more meaningful with the full dataset, but we'll simulate it\n",
    "    growth_df['YoY_Growth'] = growth_df['Value'] * 0.05  # Simulated 5% growth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Register the growth dataset\n",
    "    growth_dataset_id = catalog.register_dataset(\n",
    "        df=growth_df,\n",
    "        name=\"NZ Industry Financial Data - Growth Analysis\",\n",
    "        description=\"Financial data with year-over-year growth calculations\",\n",
    "        source=\"Derived from cleaned NZ Industry Financial Data\",\n",
    "        owner=\"Data Science Team\",\n",
    "        tags=[\"finance\", \"new zealand\", \"industry\", \"growth\", \"analysis\"],\n",
    "        additional_info={\n",
    "            \"parent_dataset\": cleaned_dataset_id,\n",
    "            \"analysis_type\": \"Year-over-year growth\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Growth analysis dataset registered with ID: {growth_dataset_id}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Record the transformation\n",
    "    catalog.record_transformation(\n",
    "        name=\"Growth Calculation\",\n",
    "        description=\"Calculate year-over-year growth for financial metrics\",\n",
    "        code=\"growth_df = cleaned_df.copy()\\ngrowth_df['YoY_Growth'] = growth_df['Value'] * 0.05\",\n",
    "        input_datasets=[cleaned_dataset_id],\n",
    "        output_dataset_id=growth_dataset_id,\n",
    "        parameters={\"growth_metric\": \"year-over-year\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddd67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Visualize the lineage\n",
    "    print(\"Visualizing data lineage...\")\n",
    "    catalog.visualize_lineage(growth_dataset_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Generate a data catalog report\n",
    "    report_path = catalog.generate_data_catalog_report()\n",
    "    print(f\"Data catalog report generated at: {report_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Print summary of the catalog\n",
    "    print(\"\\nData Catalog Summary:\")\n",
    "    print(f\"Total datasets: {len(catalog.metadata_cache)}\")\n",
    "    for dataset_id, metadata in catalog.metadata_cache.items():\n",
    "        print(f\"- {metadata.name} (ID: {dataset_id})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}